#!/usr/bin/env python3
"""Phase 4: DI Container Performance Benchmark Test

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–åŠ¹æœã‚’æ¤œè¨¼ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
- ã‚µãƒ¼ãƒ“ã‚¹è§£æ±ºæ™‚é–“æ¸¬å®šï¼ˆç›®æ¨™: <1msï¼‰
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæ¤œè¨¼
- LRUæœ€é©åŒ–ã®åŠ¹æœæ¸¬å®š
"""

import sys
import time
import statistics
from pathlib import Path
from typing import List, Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def create_test_services(container):
    """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ¼ãƒ“ã‚¹ç¾¤ã‚’ä½œæˆ"""
    
    # ä¾å­˜é–¢ä¿‚ã®ãªã„ã‚µãƒ¼ãƒ“ã‚¹
    class SimpleService:
        def __init__(self):
            self.value = "simple"
    
    # å˜ä¸€ä¾å­˜é–¢ä¿‚ã‚µãƒ¼ãƒ“ã‚¹
    class SingleDependencyService:
        def __init__(self, simple: SimpleService):
            self.simple = simple
            
    # è¤‡æ•°ä¾å­˜é–¢ä¿‚ã‚µãƒ¼ãƒ“ã‚¹
    class MultipleDependencyService:
        def __init__(self, simple: SimpleService, single: SingleDependencyService):
            self.simple = simple
            self.single = single
    
    # æ·±ã„ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒ¼ãƒ³
    class Level1Service:
        def __init__(self, multiple: MultipleDependencyService):
            self.multiple = multiple
            
    class Level2Service:
        def __init__(self, level1: Level1Service):
            self.level1 = level1
    
    # ã‚³ãƒ³ãƒ†ãƒŠã«ç™»éŒ²
    container.register_singleton(SimpleService, SimpleService)
    container.register_transient(SingleDependencyService, SingleDependencyService)
    container.register_scoped(MultipleDependencyService, MultipleDependencyService)
    container.register_transient(Level1Service, Level1Service)
    container.register_transient(Level2Service, Level2Service)
    
    return {
        'SimpleService': SimpleService,
        'SingleDependencyService': SingleDependencyService,
        'MultipleDependencyService': MultipleDependencyService,
        'Level1Service': Level1Service,
        'Level2Service': Level2Service
    }

def benchmark_service_resolution(container, service_type, iterations: int = 1000) -> Dict[str, float]:
    """ã‚µãƒ¼ãƒ“ã‚¹è§£æ±ºã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    print(f"ğŸƒâ€â™‚ï¸ {service_type.__name__} ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ({iterations}å›)")
    
    times = []
    
    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æº–å‚™ï¼‰
    for _ in range(10):
        container.get_service(service_type)
    
    # å®Ÿéš›ã®æ¸¬å®š
    for i in range(iterations):
        start_time = time.perf_counter()
        service = container.get_service(service_type)
        end_time = time.perf_counter()
        
        duration_ms = (end_time - start_time) * 1000
        times.append(duration_ms)
        
        # ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£ã—ãå–å¾—ã§ããŸã“ã¨ã‚’ç¢ºèª
        assert service is not None, f"ã‚µãƒ¼ãƒ“ã‚¹å–å¾—å¤±æ•—: {service_type.__name__}"
    
    # çµ±è¨ˆè¨ˆç®—
    avg_time = statistics.mean(times)
    min_time = min(times)
    max_time = max(times)
    median_time = statistics.median(times)
    std_dev = statistics.stdev(times) if len(times) > 1 else 0
    
    # ç›®æ¨™é”æˆç¢ºèª
    target_met = avg_time < 1.0
    performance_grade = "ğŸŸ¢ EXCELLENT" if avg_time < 0.5 else "ğŸŸ¡ GOOD" if target_met else "ğŸ”´ NEEDS IMPROVEMENT"
    
    print(f"  å¹³å‡: {avg_time:.3f}ms | ä¸­å¤®å€¤: {median_time:.3f}ms | æœ€å°: {min_time:.3f}ms | æœ€å¤§: {max_time:.3f}ms")
    print(f"  æ¨™æº–åå·®: {std_dev:.3f}ms | {performance_grade} | ç›®æ¨™é”æˆ: {target_met}")
    
    return {
        'service_name': service_type.__name__,
        'average_ms': avg_time,
        'median_ms': median_time,
        'min_ms': min_time,
        'max_ms': max_time,
        'std_dev_ms': std_dev,
        'target_met': target_met,
        'iterations': iterations
    }

def benchmark_cache_effectiveness(container, service_types: List[type]) -> Dict[str, Any]:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæ¸¬å®š"""
    
    print("\nğŸ§  ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
    container._metrics = container._metrics.__class__()
    
    # è¤‡æ•°å›ã®ã‚µãƒ¼ãƒ“ã‚¹è§£æ±ºã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœã‚’æ¸¬å®š
    total_resolutions = 0
    for service_type in service_types:
        for _ in range(50):  # å„ã‚µãƒ¼ãƒ“ã‚¹ã‚’50å›è§£æ±º
            container.get_service(service_type)
            total_resolutions += 1
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
    metrics = container.get_performance_metrics()
    
    print(f"  ç·è§£æ±ºå›æ•°: {total_resolutions}")
    print(f"  å¹³å‡è§£æ±ºæ™‚é–“: {metrics.get('overall_avg_resolution_ms', 'N/A')}ms")
    print(f"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {metrics.get('cache_hit_rate_percent', 'N/A')}%")
    print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çŠ¶æ…‹: {metrics.get('status', 'N/A')}")
    
    return metrics

def run_comprehensive_benchmark():
    """åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ“Š Phase 4: DI Container Performance Benchmark")
    print("=" * 60)
    
    from core.di_container import ServiceContainer
    
    # æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã§æ¸¬å®šï¼‰
    container = ServiceContainer()
    
    # ãƒ†ã‚¹ãƒˆã‚µãƒ¼ãƒ“ã‚¹ç¾¤ä½œæˆ
    service_types = create_test_services(container)
    
    print(f"\nğŸ”§ ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹: {len(service_types)}ç¨®é¡")
    for name in service_types.keys():
        print(f"  - {name}")
    
    # å€‹åˆ¥ã‚µãƒ¼ãƒ“ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    print(f"\nğŸ å€‹åˆ¥ã‚µãƒ¼ãƒ“ã‚¹è§£æ±ºãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    print("-" * 40)
    
    benchmark_results = []
    for service_type in service_types.values():
        result = benchmark_service_resolution(container, service_type, iterations=500)
        benchmark_results.append(result)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæ¸¬å®š
    cache_metrics = benchmark_cache_effectiveness(container, list(service_types.values()))
    
    # ç·åˆè©•ä¾¡
    print(f"\nğŸ“ˆ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    # å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®å¹³å‡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    all_averages = [r['average_ms'] for r in benchmark_results]
    overall_average = statistics.mean(all_averages)
    target_achievement_rate = sum(1 for r in benchmark_results if r['target_met']) / len(benchmark_results) * 100
    
    print(f"å…¨ä½“å¹³å‡è§£æ±ºæ™‚é–“: {overall_average:.3f}ms")
    print(f"ç›®æ¨™é”æˆç‡: {target_achievement_rate:.1f}% ({sum(1 for r in benchmark_results if r['target_met'])}/{len(benchmark_results)}ã‚µãƒ¼ãƒ“ã‚¹)")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–åŠ¹æœè©•ä¾¡
    if overall_average < 1.0:
        if overall_average < 0.5:
            grade = "ğŸŒŸ OUTSTANDING"
            message = "LRUæœ€é©åŒ–ãŒæœŸå¾…ä»¥ä¸Šã®åŠ¹æœã‚’ç™ºæ®ã—ã¦ã„ã¾ã™"
        else:
            grade = "âœ… SUCCESS"
            message = "ç›®æ¨™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹(<1ms)ã‚’é”æˆã—ã¾ã—ãŸ"
    else:
        grade = "âŒ OPTIMIZATION NEEDED"
        message = "è¿½åŠ ã®æœ€é©åŒ–ãŒå¿…è¦ã§ã™"
    
    print(f"æœ€é©åŒ–è©•ä¾¡: {grade}")
    print(f"ç·è©•: {message}")
    
    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\nğŸ“‹ è©³ç´°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ")
    print("-" * 60)
    
    print("ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
    for result in sorted(benchmark_results, key=lambda x: x['average_ms']):
        status_icon = "ğŸŸ¢" if result['target_met'] else "ğŸ”´"
        print(f"  {status_icon} {result['service_name']:<25} {result['average_ms']:>6.3f}ms")
    
    print(f"\nã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ:")
    print(f"  ãƒ’ãƒƒãƒˆç‡: {cache_metrics.get('cache_hit_rate_percent', 'N/A')}%")
    print(f"  ç·è§£æ±ºæ•°: {cache_metrics.get('total_resolutions', 'N/A')}")
    print(f"  å¥å…¨æ€§: {cache_metrics.get('status', 'N/A')}")
    
    # Phase 4å®Œäº†åˆ¤å®š
    phase4_success = (
        overall_average < 1.0 and 
        target_achievement_rate >= 80 and
        cache_metrics.get('status') == 'healthy'
    )
    
    print(f"\nğŸ¯ Phase 4å®Œäº†åˆ¤å®š")
    print("=" * 60)
    
    if phase4_success:
        print("ğŸ‰ Phase 4: Testing and validation å®Œäº†æˆåŠŸ!")
        print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™é”æˆ (<1ms)")
        print("âœ… æœ€é©åŒ–åŠ¹æœç¢ºèªå®Œäº†")
        print("âœ… ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¤œè¨¼å®Œäº†")
        print("\nğŸš€ æŠ€è¡“ã®æ³‰ã‚·ãƒªãƒ¼ã‚ºåˆ¶ä½œæ”¯æ´ãƒ„ãƒ¼ãƒ«")
        print("   Phase 3-2 â†’ Phase 4 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ·æ–°å®Œäº†!")
    else:
        print("âš ï¸  Phase 4: ä¸€éƒ¨æ”¹å–„ãŒå¿…è¦")
        if overall_average >= 1.0:
            print("âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™æœªé”æˆ")
        if target_achievement_rate < 80:
            print("âŒ ç›®æ¨™é”æˆç‡ãŒä¸ååˆ†")
        if cache_metrics.get('status') != 'healthy':
            print("âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ãŒä¸ååˆ†")
    
    return phase4_success, {
        'overall_average_ms': overall_average,
        'target_achievement_rate': target_achievement_rate,
        'benchmark_results': benchmark_results,
        'cache_metrics': cache_metrics
    }

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    try:
        success, metrics = run_comprehensive_benchmark()
        
        if success:
            print(f"\nğŸ† ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: Phase 4 SUCCESS")
            sys.exit(0)
        else:
            print(f"\nâš ï¸  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: Phase 4 è¦æ”¹å–„")
            sys.exit(1)
            
    except Exception as e:
        print(f"\nâŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()