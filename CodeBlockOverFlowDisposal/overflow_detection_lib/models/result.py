#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Detection result data models
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import List, Optional
import statistics


class ConfidenceLevel(Enum):
    """æ¤œå‡ºä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«"""
    LOW = "Low"
    MEDIUM = "Med"
    HIGH = "High"
    VERY_HIGH = "VHigh"


@dataclass
class OverflowDetail:
    """å€‹åˆ¥ã¯ã¿å‡ºã—è©³ç´°ãƒ‡ãƒ¼ã‚¿"""
    
    page_number: int
    overflow_text: str
    x_position: float
    y_position: float
    overflow_amount: float
    confidence: ConfidenceLevel
    char_count: int
    
    def __str__(self) -> str:
        """æ–‡å­—åˆ—è¡¨ç¾ï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰"""
        return (f"Page {self.page_number}: '{self.overflow_text}' "
                f"at ({self.x_position:.1f}, {self.y_position:.1f}) "
                f"overflow +{self.overflow_amount:.2f}pt [{self.confidence.value}]")
    
    def to_dict(self) -> dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            'page': self.page_number,
            'text': self.overflow_text,
            'x_pos': self.x_position,
            'y_pos': self.y_position,
            'overflow': self.overflow_amount,
            'confidence': self.confidence.value,
            'char_count': self.char_count
        }


@dataclass 
class DetectionResult:
    """æ¤œå‡ºçµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    
    # åŸºæœ¬æƒ…å ±
    pdf_path: Path
    total_pages: int
    processing_time: float
    detection_timestamp: datetime = field(default_factory=datetime.now)
    
    # æ¤œå‡ºçµæœ
    detected_pages: List[int] = field(default_factory=list)
    detection_details: List[OverflowDetail] = field(default_factory=list)
    
    # å“è³ªæƒ…å ±
    processing_warnings: List[str] = field(default_factory=list)
    
    @property
    def detection_count(self) -> int:
        """æ¤œå‡ºãƒšãƒ¼ã‚¸æ•°"""
        return len(self.detected_pages)
    
    @property
    def detection_rate(self) -> float:
        """æ¤œå‡ºç‡ (%)"""
        if self.total_pages == 0:
            return 0.0
        return (self.detection_count / self.total_pages) * 100
    
    @property
    def avg_overflow_amount(self) -> float:
        """å¹³å‡ã¯ã¿å‡ºã—é‡ (pt)"""
        if not self.detection_details:
            return 0.0
        amounts = [detail.overflow_amount for detail in self.detection_details]
        return statistics.mean(amounts)
    
    @property
    def max_overflow_amount(self) -> float:
        """æœ€å¤§ã¯ã¿å‡ºã—é‡ (pt)"""
        if not self.detection_details:
            return 0.0
        amounts = [detail.overflow_amount for detail in self.detection_details]
        return max(amounts)
    
    @property
    def confidence_scores(self) -> List[float]:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ä¸€è¦§"""
        confidence_mapping = {
            ConfidenceLevel.LOW: 0.25,
            ConfidenceLevel.MEDIUM: 0.50,
            ConfidenceLevel.HIGH: 0.75,
            ConfidenceLevel.VERY_HIGH: 0.95
        }
        return [confidence_mapping.get(detail.confidence, 0.5) 
                for detail in self.detection_details]
    
    def to_page_list(self) -> str:
        """æ”¹è¡ŒåŒºåˆ‡ã‚Šã®ãƒšãƒ¼ã‚¸ãƒªã‚¹ãƒˆæ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
        if not self.detected_pages:
            return "æ¤œå‡ºã•ã‚ŒãŸã¯ã¿å‡ºã—ãƒšãƒ¼ã‚¸ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        return "\n".join(str(page) for page in sorted(self.detected_pages))
    
    def to_detailed_report(self) -> str:
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
        lines = []
        lines.append("=" * 60)
        lines.append(f"PDF ã¯ã¿å‡ºã—æ¤œå‡ºçµæœè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ")
        lines.append("=" * 60)
        lines.append("")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        lines.append("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
        lines.append(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {self.pdf_path.name}")
        lines.append(f"ç·ãƒšãƒ¼ã‚¸æ•°: {self.total_pages}")
        lines.append(f"å‡¦ç†æ™‚é–“: {self.processing_time:.2f}ç§’")
        lines.append(f"å‡¦ç†æ—¥æ™‚: {self.detection_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # æ¤œå‡ºçµ±è¨ˆ
        lines.append("ğŸ“Š æ¤œå‡ºçµ±è¨ˆ")
        lines.append(f"æ¤œå‡ºãƒšãƒ¼ã‚¸æ•°: {self.detection_count} / {self.total_pages} ({self.detection_rate:.1f}%)")
        if self.detection_details:
            lines.append(f"å¹³å‡ã¯ã¿å‡ºã—é‡: {self.avg_overflow_amount:.2f}pt")
            lines.append(f"æœ€å¤§ã¯ã¿å‡ºã—é‡: {self.max_overflow_amount:.2f}pt")
        lines.append("")
        
        # è©³ç´°çµæœ
        if self.detection_details:
            lines.append("ğŸ“‹ è©³ç´°çµæœ")
            lines.append(f"{'Page':<5} {'ã¯ã¿å‡ºã—æ–‡å­—':<15} {'ä½ç½®(pt)':<10} {'ã¯ã¿å‡ºã—é‡':<12} {'ä¿¡é ¼åº¦':<8}")
            lines.append("-" * 60)
            
            for detail in self.detection_details:
                text_preview = detail.overflow_text[:12] + "..." if len(detail.overflow_text) > 12 else detail.overflow_text
                lines.append(f"{detail.page_number:<5} {text_preview:<15} {detail.x_position:<10.1f} "
                           f"+{detail.overflow_amount:<11.2f} {detail.confidence.value:<8}")
        else:
            lines.append("ğŸ“‹ è©³ç´°çµæœ: ã¯ã¿å‡ºã—æ¤œå‡ºãªã—")
        
        # è­¦å‘Šæƒ…å ±
        if self.processing_warnings:
            lines.append("")
            lines.append("âš ï¸ å‡¦ç†è­¦å‘Š")
            for warning in self.processing_warnings:
                lines.append(f"  - {warning}")
        
        lines.append("")
        lines.append("=" * 60)
        
        return "\n".join(lines)
    
    def to_csv(self) -> str:
        """CSV å½¢å¼ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        if not self.detection_details:
            return "ãƒšãƒ¼ã‚¸,ã¯ã¿å‡ºã—æ–‡å­—,Xåº§æ¨™,Yåº§æ¨™,ã¯ã¿å‡ºã—é‡,ä¿¡é ¼åº¦,æ–‡å­—æ•°\n"
        
        lines = ["ãƒšãƒ¼ã‚¸,ã¯ã¿å‡ºã—æ–‡å­—,Xåº§æ¨™,Yåº§æ¨™,ã¯ã¿å‡ºã—é‡,ä¿¡é ¼åº¦,æ–‡å­—æ•°"]
        
        for detail in self.detection_details:
            # CSVç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            escaped_text = detail.overflow_text.replace('"', '""')
            if ',' in escaped_text or '"' in escaped_text or '\n' in escaped_text:
                escaped_text = f'"{escaped_text}"'
            
            lines.append(f"{detail.page_number},{escaped_text},{detail.x_position:.2f},"
                        f"{detail.y_position:.2f},{detail.overflow_amount:.2f},"
                        f"{detail.confidence.value},{detail.char_count}")
        
        return "\n".join(lines)
    
    def get_summary_stats(self) -> dict:
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’è¾æ›¸å½¢å¼ã§å–å¾—"""
        return {
            'total_pages': self.total_pages,
            'detected_pages': self.detection_count,
            'detection_rate': self.detection_rate,
            'processing_time': self.processing_time,
            'avg_overflow': self.avg_overflow_amount,
            'max_overflow': self.max_overflow_amount,
            'warnings_count': len(self.processing_warnings)
        }