#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Maximum OCR Detector V3 - æ§‹é€ æ”¹å–„ç‰ˆ
è¤‡é›‘åº¦20ã®é–¢æ•°ã‚’åˆ†å‰²ã—ã€ä¿å®ˆæ€§ã¨æ‹¡å¼µæ€§ã‚’å‘ä¸Š
Sequential Thinkingæ‰¹åˆ¤çš„æ¤œè¨¼ã®çµæœã‚’åæ˜ 
"""

import logging
from pathlib import Path
from typing import Dict, List, Tuple
import statistics
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    import pdfplumber
except ImportError:
    print("pdfplumber not available. Running in compatibility mode.")
    print("Install pdfplumber: pip install pdfplumber")
    sys.exit(1)

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class FalsePositiveFilters:
    """èª¤æ¤œçŸ¥ãƒ•ã‚£ãƒ«ã‚¿ç¾¤ï¼ˆåˆ†å‰²ã•ã‚ŒãŸå®Ÿè£…ï¼‰"""
    
    @staticmethod
    def is_measurement_error(overflow_amount: float) -> bool:
        """æ¸¬å®šèª¤å·®ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã¯ã¿å‡ºã—é‡ã‹ãƒã‚§ãƒƒã‚¯"""
        return overflow_amount <= 0.5
    
    @staticmethod
    def is_pdf_internal_encoding(text_content: str) -> bool:
        """PDFå†…éƒ¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–‡å­—ã‹ãƒã‚§ãƒƒã‚¯"""
        return '(cid:' in text_content
    
    @staticmethod
    def is_page_number(text_content: str) -> bool:
        """ãƒšãƒ¼ã‚¸ç•ªå·ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯"""
        return text_content.isdigit() and len(text_content) <= 3
    
    @staticmethod
    def is_japanese_only(text_content: str) -> bool:
        """æ—¥æœ¬èªæ–‡å­—ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆASCIIå¯¾è±¡å¤–ï¼‰"""
        if not text_content:
            return False
        printable_chars = [c for c in text_content if c.isprintable()]
        if not printable_chars:
            return False
        return all(ord(c) > 127 for c in printable_chars)
    
    @staticmethod
    def is_powershell_pattern(text_content: str, text_length: int) -> bool:
        """PowerShellç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ãƒã‚§ãƒƒã‚¯"""
        return '::' in text_content and text_length > 10
    
    @staticmethod
    def is_file_extension(text_content: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ãƒã‚§ãƒƒã‚¯"""
        return '.ps1' in text_content
    
    @staticmethod
    def is_short_symbol_noise(text_content: str, text_length: int) -> bool:
        """çŸ­ã„è¨˜å·ãƒã‚¤ã‚ºã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        if text_length == 1:
            char = text_content[0]
            # é‡è¦ãªè¨˜å·ã¯ä¿è­·ï¼ˆã‚³ãƒ¼ãƒ‰ã§ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ï¼‰
            protected_symbols = {
                '"', "'", '(', ')', '[', ']', '{', '}', '<', '>', 
                '=', '+', '-', '*', '/', '\\', '|', '&', '%', 
                '$', '#', '@', '!', '?', '.', ',', ';', ':'
            }
            return char not in protected_symbols and not char.isalnum()
        elif text_length == 2:
            # 2æ–‡å­—ã§ä¸¡æ–¹ã¨ã‚‚åˆ¶å¾¡è¨˜å·ã®å ´åˆã®ã¿é™¤å¤–
            excluded_symbols = {'"', "'", '(', ')', '[', ']', '{', '}', '<', '>', '=', '+', '-'}
            return all(not c.isalnum() and c not in excluded_symbols for c in text_content)
        return False
    
    @staticmethod
    def is_image_element_tag(text_content: str) -> bool:
        """ç”»åƒãƒ»ç·šè¦ç´ ã‚¿ã‚°ã‹ãƒã‚§ãƒƒã‚¯"""
        return (text_content.startswith('[IMAGE:') or 
                text_content.startswith('[LINE]') or 
                text_content.startswith('[RECT:'))
    
    @staticmethod
    def is_index_pattern(text_content: str) -> bool:
        """ç›®æ¬¡ãƒ»ç´¢å¼•ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ãƒã‚§ãƒƒã‚¯"""
        return 'â€¦â€¦' in text_content or 'ãƒ»ãƒ»ãƒ»' in text_content

class MaximumOCRDetectorV3:
    """æ§‹é€ æ”¹å–„ç‰ˆOCRæ¤œå‡ºå™¨"""
    
    def __init__(self):
        self.mm_to_pt = 2.83465
        self.filters = FalsePositiveFilters()
        self.quality_metrics = {
            'total_pages_processed': 0,
            'total_detections': 0,
            'quality_warnings': []
        }
    
    def is_ascii_char(self, char: str) -> bool:
        """ASCIIæ–‡å­—åˆ¤å®š"""
        if not char or len(char) == 0:
            return False
        return ord(char[0]) < 128
    
    def is_likely_false_positive(self, overflow_text: str, overflow_amount: float, y_position: float) -> bool:
        """æ”¹è‰¯ç‰ˆèª¤æ¤œçŸ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆåˆ†å‰²ã•ã‚ŒãŸå®Ÿè£…ï¼‰"""
        text_content = overflow_text.strip()
        text_length = len(overflow_text)
        
        # å„ãƒ•ã‚£ãƒ«ã‚¿ã‚’é †æ¬¡é©ç”¨ï¼ˆè¤‡é›‘åº¦ã‚’åˆ†æ•£ï¼‰
        if self.filters.is_measurement_error(overflow_amount):
            return True
        
        if self.filters.is_pdf_internal_encoding(text_content):
            return True
        
        if self.filters.is_page_number(text_content):
            return True
        
        if self.filters.is_japanese_only(text_content):
            return True
        
        if self.filters.is_powershell_pattern(text_content, text_length):
            return True
        
        if self.filters.is_file_extension(text_content):
            return True
        
        if self.filters.is_short_symbol_noise(text_content, text_length):
            return True
        
        if self.filters.is_image_element_tag(text_content):
            return True
        
        if self.filters.is_index_pattern(text_content):
            return True
        
        return False
    
    def detect_overflows(self, page, page_number: int) -> List[Dict]:
        """ç¢ºå®Ÿãªã¯ã¿å‡ºã—æ¤œå‡º"""
        overflows = []
        
        # ãƒãƒ¼ã‚¸ãƒ³è¨ˆç®—
        if page_number % 2 == 1:  # å¥‡æ•°ãƒšãƒ¼ã‚¸
            right_margin_pt = 10 * self.mm_to_pt  # 28.3pt
        else:  # å¶æ•°ãƒšãƒ¼ã‚¸
            right_margin_pt = 18 * self.mm_to_pt  # 51.0pt
        
        text_right_edge = page.width - right_margin_pt
        
        # è¡Œã”ã¨ã®ã¯ã¿å‡ºã—æ–‡å­—åé›†
        line_overflows = {}
        
        for char in page.chars:
            if self.is_ascii_char(char['text']):
                char_x1 = char['x1']
                if char_x1 > text_right_edge + 0.1:  # 0.1pté–¾å€¤
                    y_pos = round(char['y0'])
                    overflow_amount = char_x1 - text_right_edge
                    
                    if y_pos not in line_overflows:
                        line_overflows[y_pos] = []
                    
                    line_overflows[y_pos].append({
                        'char': char['text'],
                        'x1': char['x1'],
                        'overflow': overflow_amount
                    })
        
        # è¡Œã”ã¨ã«é›†è¨ˆã—ã€æ”¹è‰¯ç‰ˆèª¤æ¤œçŸ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
        for y_pos, chars_in_line in line_overflows.items():
            chars_in_line.sort(key=lambda x: x['x1'])
            overflow_text = ''.join([c['char'] for c in chars_in_line])
            max_overflow = max(c['overflow'] for c in chars_in_line)
            
            # æ”¹è‰¯ç‰ˆèª¤æ¤œçŸ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
            if not self.is_likely_false_positive(overflow_text, max_overflow, y_pos):
                overflows.append({
                    'y_position': y_pos,
                    'overflow_text': overflow_text,
                    'overflow_amount': max_overflow,
                    'char_count': len(chars_in_line)
                })
        
        return overflows
    
    def process_pdf_comprehensive(self, pdf_path: Path) -> List[Dict]:
        """PDFå…¨ä½“ã®å‡¦ç†ï¼ˆV3ç‰ˆï¼‰"""
        results = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                total_pages = len(pdf.pages)
                self.quality_metrics['total_pages_processed'] = total_pages
                
                logger.info(f"\n{'='*80}")
                logger.info(f"Maximum OCR Detection V3: {pdf_path.name} ({total_pages}ãƒšãƒ¼ã‚¸)")
                logger.info(f"{'='*80}")
                
                for i, page in enumerate(pdf.pages):
                    page_number = i + 1
                    page_results = self.detect_overflows(page, page_number)
                    
                    if page_results:
                        result = {
                            'page': page_number,
                            'overflows': page_results,
                            'overflow_count': len(page_results)
                        }
                        results.append(result)
                        
                        logger.info(f"\nPage {page_number}: {len(page_results)}å€‹ã®æ¤œå‡º")
                        for overflow in page_results:
                            logger.info(f"  - '{overflow['overflow_text'][:50]}' ({overflow['overflow_amount']:.2f}pt)")
        
        except Exception as e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼: {pdf_path} - {str(e)}")
            self.quality_metrics['quality_warnings'].append(f"Processing error: {str(e)}")
        
        return results
    
    def print_quality_report(self, results: List[Dict], pdf_path: Path):
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›"""
        logger.info(f"\n{'='*80}")
        logger.info(f"Maximum OCR V3 Quality Report: {pdf_path.name}")
        logger.info(f"{'='*80}")
        
        total_detections = sum(r['overflow_count'] for r in results)
        pages_with_detections = len(results)
        
        logger.info(f"å‡¦ç†ãƒšãƒ¼ã‚¸æ•°: {self.quality_metrics['total_pages_processed']}")
        logger.info(f"æ¤œå‡ºãƒšãƒ¼ã‚¸æ•°: {pages_with_detections}")
        logger.info(f"ç·æ¤œå‡ºæ•°: {total_detections}")
        
        if self.quality_metrics['quality_warnings']:
            logger.info(f"\nå“è³ªè­¦å‘Š:")
            for warning in self.quality_metrics['quality_warnings']:
                logger.info(f"  âš ï¸ {warning}")
        
        # æ¤œå‡ºè©³ç´°
        if results:
            detected_pages = [r['page'] for r in results]
            logger.info(f"\næ¤œå‡ºãƒšãƒ¼ã‚¸ãƒªã‚¹ãƒˆ: {sorted(detected_pages)}")
        
        logger.info("="*80)

def run_comprehensive_test():
    """å…¨PDFã§ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆï¼ˆV3å®Ÿè£…ï¼‰"""
    detector = MaximumOCRDetectorV3()
    pdf_files = ['sample.pdf', 'sample2.pdf', 'sample3.pdf', 'sample4.pdf', 'sample5.pdf']
    
    all_results = {}
    
    logger.info("=" * 90)
    logger.info("Maximum OCR Detector V3 - æ§‹é€ æ”¹å–„ç‰ˆæ€§èƒ½ãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 90)
    
    for pdf_file in pdf_files:
        pdf_path = Path(pdf_file)
        if not pdf_path.exists():
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pdf_path}")
            continue
        
        results = detector.process_pdf_comprehensive(pdf_path)
        detector.print_quality_report(results, pdf_path)
        
        # çµæœã‚’ä¿å­˜
        detected_pages = [r['page'] for r in results]
        all_results[pdf_file] = detected_pages
    
    # æ€§èƒ½è©•ä¾¡ï¼ˆç¾å®Ÿçš„è©•ä¾¡ï¼‰
    ground_truth = {
        'sample.pdf': [48],
        'sample2.pdf': [128, 129],
        'sample3.pdf': [13, 35, 36, 39, 42, 44, 45, 47, 49, 62, 70, 78, 80, 106, 115, 122, 124],
        'sample4.pdf': [27, 30, 38, 73, 75, 76],
        'sample5.pdf': [128, 129]
    }
    
    # V2ã¨ã®æ¯”è¼ƒ
    v2_results = {
        'sample.pdf': [],
        'sample2.pdf': [],
        'sample3.pdf': [13, 35, 36, 39, 42, 44, 45, 47, 49, 62, 70, 75, 78, 79, 115, 121, 122, 124, 125],
        'sample4.pdf': [27, 30, 38, 73, 76],
        'sample5.pdf': []
    }
    
    def calculate_metrics(results_dict):
        total_expected = sum(len(pages) for pages in ground_truth.values())
        total_detected = sum(len(pages) for pages in results_dict.values())
        
        true_positives = 0
        false_positives = 0
        false_negatives = 0
        
        for pdf_file, expected in ground_truth.items():
            detected = results_dict.get(pdf_file, [])
            
            tp = len([p for p in detected if p in expected])
            fp = len([p for p in detected if p not in expected])
            fn = len([p for p in expected if p not in detected])
            
            true_positives += tp
            false_positives += fp
            false_negatives += fn
        
        recall = true_positives / total_expected if total_expected > 0 else 0
        precision = true_positives / total_detected if total_detected > 0 else 1.0
        
        return {
            'recall': recall,
            'precision': precision,
            'true_positives': true_positives,
            'false_positives': false_positives,
            'false_negatives': false_negatives,
            'total_detected': total_detected
        }
    
    v2_metrics = calculate_metrics(v2_results)
    v3_metrics = calculate_metrics(all_results)
    
    logger.info(f"\nğŸ“Š V2 vs V3 æ€§èƒ½æ¯”è¼ƒï¼ˆç¾å®Ÿçš„è©•ä¾¡ï¼‰:")
    logger.info("-" * 70)
    logger.info(f"{'æŒ‡æ¨™':<15} {'V2':<15} {'V3':<15} {'æ”¹å–„':<15}")
    logger.info("-" * 70)
    logger.info(f"{'Recall':<15} {v2_metrics['recall']:<14.1%} {v3_metrics['recall']:<14.1%} {v3_metrics['recall']-v2_metrics['recall']:+.1%}")
    logger.info(f"{'Precision':<15} {v2_metrics['precision']:<14.1%} {v3_metrics['precision']:<14.1%} {v3_metrics['precision']-v2_metrics['precision']:+.1%}")
    logger.info(f"{'æ¤œå‡ºãƒšãƒ¼ã‚¸æ•°':<15} {v2_metrics['total_detected']:<14} {v3_metrics['total_detected']:<14} {v3_metrics['total_detected']-v2_metrics['total_detected']:+}")
    logger.info(f"{'æ­£æ¤œå‡º':<15} {v2_metrics['true_positives']:<14} {v3_metrics['true_positives']:<14} {v3_metrics['true_positives']-v2_metrics['true_positives']:+}")
    logger.info(f"{'èª¤æ¤œå‡º':<15} {v2_metrics['false_positives']:<14} {v3_metrics['false_positives']:<14} {v3_metrics['false_positives']-v2_metrics['false_positives']:+}")
    logger.info(f"{'è¦‹é€ƒã—':<15} {v2_metrics['false_negatives']:<14} {v3_metrics['false_negatives']:<14} {v3_metrics['false_negatives']-v2_metrics['false_negatives']:+}")
    
    logger.info(f"\nğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³ï¼ˆç¾å®Ÿçš„è©•ä¾¡ï¼‰:")
    logger.info("-" * 50)
    logger.info(f"Phase 1ç›®æ¨™ï¼ˆ78%ï¼‰: {'âœ… é”æˆ' if v3_metrics['recall'] >= 0.78 else 'âŒ æœªé”æˆ'}")
    logger.info(f"æœ€çµ‚ç›®æ¨™ï¼ˆ85%ï¼‰  : {'âœ… é”æˆ' if v3_metrics['recall'] >= 0.85 else 'âŒ æœªé”æˆ'}")
    logger.info(f"V3 Recall         : {v3_metrics['recall']:.1%}")
    
    if v3_metrics['recall'] < 0.78:
        needed_additional = int(28 * (0.78 - v3_metrics['recall']))
        logger.info(f"âŒ Phase 1ç›®æ¨™æœªé”æˆã€{needed_additional}ãƒšãƒ¼ã‚¸ã®è¿½åŠ æ”¹å–„ãŒå¿…è¦")
    else:
        logger.info(f"âœ… Phase 1ç›®æ¨™é”æˆæ¸ˆã¿")
    
    logger.info("\nğŸ—ï¸ æ§‹é€ æ”¹å–„æˆæœ:")
    logger.info("- è¤‡é›‘åº¦20é–¢æ•°ã‚’9ã¤ã®å˜ç´”é–¢æ•°ã«åˆ†å‰²")
    logger.info("- FalsePositiveFiltersã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚‹è²¬ä»»åˆ†é›¢")
    logger.info("- å„ãƒ•ã‚£ãƒ«ã‚¿ã®ç‹¬ç«‹ãƒ†ã‚¹ãƒˆãŒå¯èƒ½")
    logger.info("- ä¿å®ˆæ€§ã¨ãƒ‡ãƒãƒƒã‚°å®¹æ˜“æ€§ã®å¤§å¹…å‘ä¸Š")
    
    logger.info("=" * 90)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Maximum OCR Detector V3')
    parser.add_argument('--test', action='store_true', help='åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ')
    parser.add_argument('pdf_files', nargs='*', help='å‡¦ç†ã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«')
    args = parser.parse_args()
    
    if args.test:
        run_comprehensive_test()
    else:
        detector = MaximumOCRDetectorV3()
        
        for pdf_file in args.pdf_files:
            pdf_path = Path(pdf_file)
            if not pdf_path.exists():
                logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pdf_path}")
                continue
            
            results = detector.process_pdf_comprehensive(pdf_path)
            detector.print_quality_report(results, pdf_path)

if __name__ == "__main__":
    main()